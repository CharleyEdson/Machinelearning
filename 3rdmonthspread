from statsmodels.tsa.ar_model import AutoReg

from sklearn.metrics import mean_squared_error
from math import sqrt
from pandas import read_csv
from matplotlib import pyplot as plt
from pandas.plotting import lag_plot as lag
from pandas import DataFrame
from pandas import concat
from pandas.plotting import autocorrelation_plot as auto_corr
from statsmodels.graphics.tsaplots import plot_acf
# load dataset
series = read_csv('c:\CE Management\Energy\Regression\\third_month_spread2.csv', header=0, index_col=0)
#print(series.head())
series.plot()
plt.show()
#graphs a values on x, and on y t+1
#lag(series)
#plt.show()

#just this code is creating a lagged dataset
values = DataFrame(series.values)
dataframe = concat([values.shift(1), values], axis = 1)
dataframe.columns = ['t-1', 't+1']
'''
#Builds a correlation between all columns
result = dataframe.corr()
print(result)'''

''' Auto correlation for each Lag
auto_corr(series)
plt.show()
as a line chart
plot_acf(series, lags=31)
plt.show()'''
#Now to build the persistence model
#split into train and test sets

'''X = dataframe.values

train, test = X[1:len(X)-7], X[len(X)-7:]
train_X, train_y = train[:,0], train[:,1]
test_X, test_y = test[:,0], test[:,1]'''

#Persistence model
def model_persistence(x):
    return x

#walk-forward validation
'''predictions = []
for x in test_X:
    yhat = model_persistence(x)
    predictions.append(yhat)
test_score = mean_squared_error(test_y, predictions)
print('Test MSE: %.3f' % test_score)
#plot prediction vs expected
plt.plot(test_y)
plt.plot(predictions, color = 'red')
plt.show()'''

# split dataset Running an AR model
X = series.values
train, test = X[1:len(X)-7], X[len(X)-7:]
#train autoregression
model = AutoReg(train, lags=50)
model_fit = model.fit()
print('Coefficients: %s' % model_fit.params)
#make predictions
predictions = model_fit.predict(start = len(train), end = len(train) + len(test)-1, dynamic=False)
for i in range(len(predictions)):
    print('predicted=%f, expected=%f' % (predictions[i], test[i]))
rmse = sqrt(mean_squared_error(test, predictions))
print('Test RMSe: %.3f' % rmse)
plt.plot(test)
plt.plot(predictions, color='red')
plt.show()
##############################################################################################################
#second part
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.metrics import mean_squared_error
from math import sqrt
from statsmodels.tsa.ar_model import AutoReg
from matplotlib import pyplot
series = read_csv('c:\CE Management\Energy\Regression\\third_month_spread2.csv', header=0, index_col=0)
#print(series.head())

values = DataFrame(series.values)
dataframe = concat([values.shift(1), values], axis=1)
dataframe.columns = ['t-1', 't+1']

# split into train and test sets
X = dataframe.values
train_size = int(len(X) * 0.66)
train, test = X[1:train_size], X[train_size:]
train_X, train_y = train[:,0], train[:,1]
test_X, test_y = test[:,0], test[:,1]
'''# persistence model
predictions = [x for x in test_X]
# skill of persistence model
rmse = sqrt(mean_squared_error(test_y, predictions))
print('Test RMSE: %.3f' % rmse)
# calculate residuals
residuals = [test_y[i]-predictions[i] for i in range(len(predictions))]
residuals = DataFrame(residuals)
print(residuals.head())
# persistence model on training set
train_pred = [x for x in train_X]
# calculate residuals
train_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]
# model the training set residuals
model = AutoReg(train_resid, lags=15)
model_fit = model.fit()
print('Coef=%s' % (model_fit.params))'''
# persistence model on training set
train_pred = [x for x in train_X]
# calculate residuals
train_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]
# model the training set residuals
window = 15
model = AutoReg(train_resid, lags=window)
model_fit = model.fit()
coef = model_fit.params
'''# walk forward over time steps in test
history = train_resid[len(train_resid)-window:]
history = [history[i] for i in range(len(history))]
predictions = list()
expected_error = list()
for t in range(len(test_y)):
	# persistence
	yhat = test_X[t]
	error = test_y[t] - yhat
	expected_error.append(error)
	# predict error
	length = len(history)
	lag = [history[i] for i in range(length-window,length)]
	pred_error = coef[0]
	for d in range(window):
		pred_error += coef[d+1] * lag[window-d-1]
	predictions.append(pred_error)
	history.append(error)
	print('predicted error=%f, expected error=%f' % (pred_error, error))
# plot predicted error.
#the previous code modeled the residual errors.
pyplot.plot(expected_error)
pyplot.plot(predictions, color='red')
pyplot.show()'''
# walk forward over time steps in test
history = train_resid[len(train_resid)-window:]
history = [history[i] for i in range(len(history))]
predictions = list()
for t in range(len(test_y)):
	# persistence
	yhat = test_X[t]
	error = test_y[t] - yhat
	# predict error
	length = len(history)
	lag = [history[i] for i in range(length-window,length)]
	pred_error = coef[0]
	for d in range(window):
		pred_error += coef[d+1] * lag[window-d-1]
	# correct the prediction
	yhat = yhat + pred_error
	predictions.append(yhat)
	history.append(error)
	print('predicted=%f, expected=%f' % (yhat, test_y[t]))
# error
rmse = sqrt(mean_squared_error(test_y, predictions))
print('Test RMSE: %.3f' % rmse)
# plot predicted error
pyplot.plot(test_y)
pyplot.plot(predictions, color='red', alpha = 0.5)
pyplot.show()
print(model.forecast(10))
